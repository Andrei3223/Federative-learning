model:
  _target_: src.models.SASRec
  args:
    bert_max_len: 10
    num_items: 10
    bert_num_blocks: 6
    bert_hidden_units: 8
    bert_dropout: 0.4
    device: cuda

trainer:
  max_len: 50
  batch_size: 512
  n_epochs: 301
  l2_emb: 5e-5
  weight_decay: 0.0001
  val_freq: 15
  save_freq: 30
  device: cuda # device name or "auto"
optimizer:
  _target_: torch.optim.AdamW
  lr: 1e-3
lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  step_size: 10
  gamma: 0.95
  # _target_: torch.optim.lr_scheduler.OneCycleLR
  # max_lr: 7e-4
  # pct_start: 0.1
  # steps_per_epoch: ${trainer.epoch_len}
  # epochs: ${trainer.n_epochs}
  # anneal_strategy: cos
loss_function:
  _target_: torch.nn.BCEWithLogitsLoss
dataset:
  min_hist_len: 4  # user has minimum k interactions, each item at least k times in dataset
  # data_path: data/datasets_5/Movies_and_TV_5.json
  data_path: /kaggle/working/Video_Games_5.json
  name: video_games
  # data_path: data/datasets_5/Kindle_Store_5.json
  # name: kindle
  # data_path: data/datasets_5/Office_Products_5.json
  # name: office
# self.config["trainer"]["max_grad_norm"]

wandb:
  project: "federative_learning"
  log_checkpoints: True
  entity: null
  run_name: "bert_video"
  mode: "online"